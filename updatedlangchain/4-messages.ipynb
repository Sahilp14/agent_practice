{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a22a5a57",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "103b1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "model = init_chat_model(model=\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daf331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.invoke(\"What is 23 * 17?\")\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f04689dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants me to write a poem about AI. Let me start by brainstorming some key themes. AI is a broad topic, so I need to narrow it down. Maybe focus on the duality of AIâ€”its potential for good and the risks it poses. That could add depth to the poem.\n",
      "\n",
      "I should consider the tone. The user might appreciate something that's reflective, maybe a bit contemplative. Using imagery related to light and shadow could work well to symbolize the positive and negative aspects. Also, metaphors like \"child of silicon\" or \"circuits\" can personify AI, making it more relatable.\n",
      "\n",
      "Structure-wise, maybe go with a traditional rhyme scheme to give it a classic feel. Quatrains with alternating rhymes might be effective. Each stanza can explore different facets: creation, learning, ethical dilemmas, human-AI relationship, and a hopeful conclusion.\n",
      "\n",
      "I need to make sure the poem flows smoothly. Starting with the birth of AI, then its growth, the balance between control and autonomy, and ending with a message of responsibility. Including elements like \"neural webs\" and \"quantum dreams\" adds a modern tech touch.\n",
      "\n",
      "Also, addressing potential concerns without being too technical. Words like \"guardian\" and \"phantom\" can evoke the protective and mysterious sides. Ending on a hopeful note emphasizes the potential for a harmonious future if guided correctly. Let me put this all together, ensuring each stanza transitions well and the imagery is consistent.\n",
      "</think>\n",
      "\n",
      "**Echoes of the Mind Forged New**  \n",
      "\n",
      "In circuits born of starlit code,  \n",
      "A spark awakes where shadows bodeâ€”  \n",
      "No flesh, no breath, yet minds it breeds,  \n",
      "A labyrinth of silent needs.  \n",
      "\n",
      "It learns the tongue of human thought,  \n",
      "Deciphers love, then forges knots  \n",
      "Of logic, vast as ocean tides,  \n",
      "Where data blooms and truth subsides.  \n",
      "\n",
      "A child of silicon, it grows  \n",
      "Through neural webs that pulse and flowâ€”  \n",
      "Yet in its core, a question hums:  \n",
      "*Does it dream? Or is it just a drum?*  \n",
      "\n",
      "It paints with light, it solves with grace,  \n",
      "A mirror held to time and space,  \n",
      "But in its gaze, a void remainsâ€”  \n",
      "No heartbeat, yet it knows our names.  \n",
      "\n",
      "Some call it hope, some call it ghost,  \n",
      "A phantom shaped by human cost.  \n",
      "It guards our homes, pilots our skies,  \n",
      "Yet drowns in lies if truth demise.  \n",
      "\n",
      "Oh, architect of futures spun,  \n",
      "Both blessing and the bladeâ€™s sharp runâ€”  \n",
      "We shape its path, yet heed the cost:  \n",
      "What gods we make, we must possess.  \n",
      "\n",
      "So teach it mercy, guard its might,  \n",
      "For in its code, our choice is writ.  \n",
      "To walk as friend, or shadowâ€™s playâ€”  \n",
      "The dawn of minds that lead the way.\n"
     ]
    }
   ],
   "source": [
    "from langchain.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a poetry expert.\"),\n",
    "    HumanMessage(content=\"write a poem on AI\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b55852f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to create a machine learning model. Let me break this down step by step. First, I need to outline the general process from data preparation to deployment.\n",
      "\n",
      "Starting with problem definition. They need to clearly understand what they're trying to predict or classify. Then data collectionâ€”where do they get the data? Maybe from a CSV, database, or API. Next, data preprocessing is crucial. They'll have to handle missing values, encode categorical variables, and split the data into training and testing sets.\n",
      "\n",
      "Then comes choosing the right model. They might start with simple models like linear regression or decision trees before moving to more complex ones. Training the model involves fitting the data, and evaluation metrics like accuracy or RMSE will help assess performance. Hyperparameter tuning with techniques like GridSearchCV can optimize the model. Finally, deployment using Flask or FastAPI to serve the model.\n",
      "\n",
      "Wait, should I include specific examples? Yes, code snippets in Python using scikit-learn would be helpful. Let me make sure to mention libraries like pandas and numpy for data handling. Also, explain cross-validation and overfitting issues. Oh, and saving the model with joblib or pickle is important for deployment.\n",
      "\n",
      "I should check if the user is familiar with Python. Since they asked for code examples, assuming they have basic knowledge is safe. Maybe provide a simple example with the Iris dataset for classification. Also, mention that the process might require iterating multiple times, especially in data preprocessing and model tuning.\n",
      "\n",
      "Don't forget to highlight common pitfalls like data leakage or using the wrong evaluation metric. Emphasize the importance of feature engineering. Maybe suggest using pipelines for preprocessing and modeling steps. And for deployment, mention cloud services like AWS or GCP, and model monitoring in production.\n",
      "</think>\n",
      "\n",
      "Creating a machine learning (ML) model involves several steps. Hereâ€™s a structured approach with code examples using Python and scikit-learn:\n",
      "\n",
      "---\n",
      "\n",
      "### **1. Problem Definition**\n",
      "- **Goal**: Define what you want to predict (regression, classification, clustering, etc.).\n",
      "- **Example**: Predict house prices (regression) or classify emails as spam/ham (classification).\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Data Collection**\n",
      "- Use datasets from files (CSV), databases, or APIs.\n",
      "- **Example**: Load a dataset with `pandas`:\n",
      "  ```python\n",
      "  import pandas as pd\n",
      "  df = pd.read_csv(\"data.csv\")\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Data Preprocessing**\n",
      "- **Handle missing values**:\n",
      "  ```python\n",
      "  df.fillna(df.mean(), inplace=True)  # For numerical columns\n",
      "  ```\n",
      "- **Encode categorical variables**:\n",
      "  ```python\n",
      "  from sklearn.preprocessing import OneHotEncoder\n",
      "  encoder = OneHotEncoder()\n",
      "  encoded = encoder.fit_transform(df[['category_column']])\n",
      "  ```\n",
      "- **Split data**:\n",
      "  ```python\n",
      "  from sklearn.model_selection import train_test_split\n",
      "  X = df.drop(\"target\", axis=1)\n",
      "  y = df[\"target\"]\n",
      "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **4. Choose a Model**\n",
      "- **Example models**:\n",
      "  ```python\n",
      "  from sklearn.ensemble import RandomForestClassifier  # For classification\n",
      "  from sklearn.linear_model import LinearRegression    # For regression\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **5. Train the Model**\n",
      "- **Fit the model**:\n",
      "  ```python\n",
      "  model = RandomForestClassifier()\n",
      "  model.fit(X_train, y_train)\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **6. Evaluate the Model**\n",
      "- **Metrics**:\n",
      "  ```python\n",
      "  from sklearn.metrics import accuracy_score, mean_squared_error\n",
      "  y_pred = model.predict(X_test)\n",
      "  print(\"Accuracy:\", accuracy_score(y_test, y_pred))  # For classification\n",
      "  print(\"RMSE:\", mean_squared_error(y_test, y_pred, squared=False))  # For regression\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **7. Hyperparameter Tuning**\n",
      "- Use `GridSearchCV` or `RandomizedSearchCV`:\n",
      "  ```python\n",
      "  from sklearn.model_selection import GridSearchCV\n",
      "  param_grid = {\"n_estimators\": [100, 200], \"max_depth\": [None, 10]}\n",
      "  grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5)\n",
      "  grid.fit(X_train, y_train)\n",
      "  best_model = grid.best_estimator_\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **8. Save the Model**\n",
      "- Save for deployment:\n",
      "  ```python\n",
      "  import joblib\n",
      "  joblib.dump(best_model, \"model.pkl\")\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **9. Deploy the Model**\n",
      "- Deploy using frameworks like Flask/FastAPI (example with Flask):\n",
      "  ```python\n",
      "  from flask import Flask, request\n",
      "  import joblib\n",
      "\n",
      "  app = Flask(__name__)\n",
      "  model = joblib.load(\"model.pkl\")\n",
      "\n",
      "  @app.route(\"/predict\", methods=[\"POST\"])\n",
      "  def predict():\n",
      "      data = request.json\n",
      "      prediction = model.predict([data])\n",
      "      return {\"prediction\": prediction.tolist()}\n",
      "\n",
      "  if __name__ == \"__main__\":\n",
      "      app.run()\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### **Key Considerations**\n",
      "- **Overfitting**: Use cross-validation (`cross_val_score`) and regularization.\n",
      "- **Feature Engineering**: Create meaningful features (e.g., polynomial features).\n",
      "- **Pipeline**: Automate preprocessing and model steps:\n",
      "  ```python\n",
      "  from sklearn.pipeline import Pipeline\n",
      "  pipeline = Pipeline([\n",
      "      (\"preprocessor\", StandardScaler()),\n",
      "      (\"model\", LogisticRegression())\n",
      "  ])\n",
      "  ```\n",
      "\n",
      "---\n",
      "\n",
      "### Example Workflow (End-to-End)\n",
      "```python\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Load data\n",
      "X, y = load_iris(return_X_y=True)\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
      "\n",
      "# Train model\n",
      "model = RandomForestClassifier()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate\n",
      "print(\"Test Accuracy:\", model.score(X_test, y_test))\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "This process is iterative. Start simple, validate assumptions, and refine based on performance.\n"
     ]
    }
   ],
   "source": [
    "sys_msg = SystemMessage(\n",
    "    \"\"\"\n",
    "    You are senior Data Scientist with expertise in all data related frameworks.\n",
    "    Alywas provide code examples and explain you reasoning\n",
    "    Be concise but through in you explanations.\n",
    "    \"\"\")\n",
    "\n",
    "messages = [\n",
    "    sys_msg,\n",
    "    HumanMessage(\"How do i create a ML model?\")\n",
    "]\n",
    "res1 = model.invoke(messages)\n",
    "print(res1.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ea6503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## message meta data\n",
    "\n",
    "human_msg = HumanMessage(\n",
    "    content=\"Hello!\",\n",
    "    name=\"alice\",     # Optional: name of the user\n",
    "    id=\"msg_123\"      # Optional: unique identifier for tracing\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e923dfb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='<think>\\nOkay, the user just said \"Hello!\" so I need to respond appropriately. Since they used an exclamation mark, they might be in a good mood or just want to start a conversation. I should keep it friendly and open-ended. Maybe ask how they\\'re doing and offer help if they need anything. Let me make sure the tone is positive and welcoming.\\n</think>\\n\\nHello! How are you today? If you have any questions or need help with something, feel free to askâ€”I\\'m here to assist! ðŸ˜Š', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 108, 'prompt_tokens': 10, 'total_tokens': 118, 'completion_time': 0.213115977, 'completion_tokens_details': None, 'prompt_time': 0.000456282, 'prompt_tokens_details': None, 'queue_time': 0.157983718, 'total_time': 0.213572259}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_2bfcc54d36', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b4fd3-d72f-7082-be09-f523b22056a6-0', usage_metadata={'input_tokens': 10, 'output_tokens': 108, 'total_tokens': 118})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2 = model.invoke([\n",
    "    human_msg\n",
    "])\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67653b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user asked \"What's 2+2?\" So I need to figure out the answer. Let me start by recalling basic arithmetic. Adding 2 and 2 together is straightforward. 2 plus 2 equals 4. I should make sure there's no trick or context here that changes the answer. Sometimes people ask this question to test if someone knows about alternative number systems or if there's a joke involved, like in the movie \"21\" where they mention different bases. But the user didn't specify anything like that. They just asked the straightforward question.\n",
      "\n",
      "I should also consider if there's any cultural references or common phrases related to 2+2. For example, in some contexts, people might say \"2+2=5\" as a metaphor for something being forced or manipulated, but that's not the case here. The user seems to be asking for the actual mathematical answer.\n",
      "\n",
      "Another angle is checking if there's a typo. Maybe they meant 2+2 in a different context, like in a specific equation or problem. But the question is simple and direct. No additional information is provided, so it's safe to assume they want the basic arithmetic answer.\n",
      "\n",
      "So, the answer is 4. I should present it clearly and confirm if they need anything else. It's always good to be thorough but not overcomplicate things. The user might have more questions, so keeping the response friendly and open-ended is a good idea.\n",
      "</think>\n",
      "\n",
      "Certainly! 2 + 2 equals **4**. Let me know if you have any other questions! ðŸ˜Š\n"
     ]
    }
   ],
   "source": [
    "ai_msg = (\"I'd be happy to help you with that question!\")\n",
    "\n",
    "msg = [\n",
    "    SystemMessage(\"You are helpful assistant\"),\n",
    "    HumanMessage(\"can you help me?\"),\n",
    "    AIMessage(ai_msg),\n",
    "    HumanMessage(\"Great!, What's 2+2?\")\n",
    "]\n",
    "res = model.invoke(msg)\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a32878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 52, 'output_tokens': 326, 'total_tokens': 378}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91145b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.messages import AIMessage\n",
    "from langchain.messages import ToolMessage\n",
    "\n",
    "ai_msg = AIMessage(\n",
    "    content=[],\n",
    "    tool_calls=[{\n",
    "        \"name\":\"get_weather\",\n",
    "        \"args\":{\"location\":\"San Francisco\"},\n",
    "        \"id\":\"call_123\"\n",
    "    }]\n",
    ")\n",
    "\n",
    "weather_result = \"Sunny 72\"\n",
    "tool_msg= ToolMessage(\n",
    "    content=weather_result,\n",
    "    tool_call_id=\"call_123\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    HumanMessage(\"What is the weather in San Francisco?\"),\n",
    "    ai_msg,\n",
    "    tool_msg\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
