{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48e31ba0",
   "metadata": {},
   "source": [
    "### Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90baad7",
   "metadata": {},
   "source": [
    "Models can be requested to provide their response in a format matching a given schema. This is a useful for ensuring the ouput can be easily parsed and used by subsequent processing. Langchain supports multiple schema types and methods for enforcing structured output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c51341",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26277c16",
   "metadata": {},
   "source": [
    "Pydantic models provide the richest feature set with validation, description, and nested structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ad855b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "os.environ['GROQ_API_KEY'] = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# model = init_chat_model(\"groq:openai/gpt-oss-120b\")\n",
    "model = init_chat_model(\"groq:qwen/qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6e9926f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(description=\"The title of the movie\")\n",
    "    year: int = Field(description=\"The release year of movie\")\n",
    "    director: str = Field(description=\"The director of the movie\")\n",
    "    rating: float = Field(description=\"The rating of the movie out of 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3169cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_structure = model.with_structured_output(Movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e9684f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Titanic' year=1997 director='James Cameron' rating=7.8\n"
     ]
    }
   ],
   "source": [
    "res = model_with_structure.invoke(\"provide details about movie titanic\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fae914",
   "metadata": {},
   "source": [
    "Message output alongside Parsed Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2a91d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Movie(BaseModel):\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    year: int = Field(..., description=\"The release year of movie\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    rating: float = Field(..., description=\"The rating of the movie out of 10\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(Movie, include_raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91a861a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw': AIMessage(content='', additional_kwargs={'reasoning_content': \"Okay, the user is asking for details about the movie Titanic. Let me see. I need to use the Movie function provided. The required parameters are title, year, director, and rating. I remember Titanic was directed by James Cameron. The release year was 1997, I think. The rating is probably high, maybe around 7.8 or so. Let me double-check those details. Yep, director is James Cameron, year 1997, and the IMDb rating is 7.8. Alright, I'll structure the function call with those parameters.\\n\", 'tool_calls': [{'id': '5qrp53t49', 'function': {'arguments': '{\"director\":\"James Cameron\",\"rating\":7.8,\"title\":\"Titanic\",\"year\":1997}', 'name': 'Movie'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 167, 'prompt_tokens': 225, 'total_tokens': 392, 'completion_time': 0.286289921, 'completion_tokens_details': {'reasoning_tokens': 119}, 'prompt_time': 0.011082788, 'prompt_tokens_details': None, 'queue_time': 0.056141312, 'total_time': 0.297372709}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None, 'model_provider': 'groq'}, id='lc_run--019b5489-f0e0-7171-8d36-3371cdead8b5-0', tool_calls=[{'name': 'Movie', 'args': {'director': 'James Cameron', 'rating': 7.8, 'title': 'Titanic', 'year': 1997}, 'id': '5qrp53t49', 'type': 'tool_call'}], usage_metadata={'input_tokens': 225, 'output_tokens': 167, 'total_tokens': 392, 'output_token_details': {'reasoning': 119}}), 'parsed': Movie(title='Titanic', year=1997, director='James Cameron', rating=7.8), 'parsing_error': None}\n"
     ]
    }
   ],
   "source": [
    "res = model_with_structure.invoke(\"provide details about movie titanic\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d185ca28",
   "metadata": {},
   "source": [
    "### Nested Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3a049cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Actor(BaseModel):\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class MovieDetails(BaseModel):\n",
    "    title: str\n",
    "    year: int\n",
    "    cast: list[Actor]\n",
    "    genres: list[str]\n",
    "    budget: float | None = Field(None, description=\"The budget of the movie in millions USD\")\n",
    "\n",
    "model_with_structure = model.with_structured_output(MovieDetails)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "baa45549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title='Inception' year=2010 cast=[Actor(name='Leonardo DiCaprio', role='Dom Cobb'), Actor(name='Joseph Gordon-Levitt', role='Arthur'), Actor(name='Ellen Page', role='Ariadne')] genres=['Science Fiction', 'Action'] budget=160.0\n"
     ]
    }
   ],
   "source": [
    "response = model_with_structure.invoke(\"provide details about movie Inception\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde10ba1",
   "metadata": {},
   "source": [
    "### TypedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b067423b",
   "metadata": {},
   "source": [
    "TypedDict provieds a simple alternative using Python's built-in Typing, ideal when you don't need runtime validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bb6dd244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'director': 'James Cameron', 'rating': 7.8, 'title': 'Titanic', 'year': 1997}\n"
     ]
    }
   ],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "class MovieDict(TypedDict):\n",
    "    title: Annotated[str, ..., \"The title of the movie\"]\n",
    "    year: Annotated[int, ..., \"The release year of movie\"]\n",
    "    director: Annotated[str, ..., \"The director of the movie\"]\n",
    "    rating: Annotated[float, ..., \"The rating of the movie out of 10\"]\n",
    "\n",
    "model_with_typeddict = model.with_structured_output(MovieDict)\n",
    "res1 = model_with_typeddict.invoke(\"provide details about movie titanic\")\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed07b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'budget': 200000000, 'cast': [{'name': 'Leonardo DiCaprio', 'role': 'Jack Dawson'}, {'name': 'Kate Winslet', 'role': 'Rose DeWitt Bukater'}, {'name': 'Billy Zane', 'role': 'Caledon Hockley'}, {'name': 'Kathy Bates', 'role': 'Molly Brown'}, {'name': 'Frances Fisher', 'role': 'Ruth DeWitt Bukater'}], 'genres': ['Drama', 'Romance'], 'title': 'Titanic', 'year': 1997}\n"
     ]
    }
   ],
   "source": [
    "class Actor(TypedDict):\n",
    "    name: str\n",
    "    role: str\n",
    "\n",
    "class MovieDetails(TypedDict):\n",
    "    title: str\n",
    "    year: int\n",
    "    cast: list[Actor]\n",
    "    genres: list[str]\n",
    "    budget: float | None = Field(None, description=\"The budget of the movie in millions USD\")\n",
    "\n",
    "model_with_typeddict = model.with_structured_output(MovieDetails)\n",
    "res2 = model_with_typeddict.invoke(\"provide details about movie titanic\")\n",
    "print(res2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a8de339c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_input_tokens': 131072,\n",
       " 'max_output_tokens': 16384,\n",
       " 'image_inputs': False,\n",
       " 'audio_inputs': False,\n",
       " 'video_inputs': False,\n",
       " 'image_outputs': False,\n",
       " 'audio_outputs': False,\n",
       " 'video_outputs': False,\n",
       " 'reasoning_output': True,\n",
       " 'tool_calling': True}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac27010",
   "metadata": {},
   "source": [
    "### Data Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba1105a",
   "metadata": {},
   "source": [
    "A data class typically contaning mainly data, although there aren't really any restrictinos. You create it using the @dataclass decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d49fe953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ea173985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='John Doe' email='john@example.com' phone='(555) 123-4567'\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information for a person\"\"\"\n",
    "    name: str = Field(description=\"Name of person\")\n",
    "    email: str = Field(description=\"Email of person\")\n",
    "    phone: str = Field(description=\"Phone number of person\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "model = create_agent(\n",
    "    model = llm,\n",
    "    response_format = ContactInfo    # Autoselecs provider stratergy\n",
    ")\n",
    "\n",
    "result = model.invoke({\n",
    "    \"messages\":[{\"role\":\"user\", \"content\":\"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})\n",
    "\n",
    "print(result['structured_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db05ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unable to import langchain_google_vertexai. Please install with `pip install -U langchain-google-vertexai`",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     email: \u001b[38;5;28mstr\u001b[39m\n\u001b[32m      9\u001b[39m     phone: \u001b[38;5;28mstr\u001b[39m \n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m agent = \u001b[43mcreate_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-1.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mContactInfo\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Autoselecs provider stratergy\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m result = agent.invoke({\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m:[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mExtract contact info from: John Doe, john@example.com, (555) 123-4567\u001b[39m\u001b[33m\"\u001b[39m}]\n\u001b[32m     17\u001b[39m })  \n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(result[\u001b[33m'\u001b[39m\u001b[33mstructured_response\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\langchainupdated\\.venv\\Lib\\site-packages\\langchain\\agents\\factory.py:686\u001b[39m, in \u001b[36mcreate_agent\u001b[39m\u001b[34m(model, tools, system_prompt, middleware, response_format, state_schema, context_schema, checkpointer, store, interrupt_before, interrupt_after, debug, name, cache)\u001b[39m\n\u001b[32m    684\u001b[39m \u001b[38;5;66;03m# init chat model\u001b[39;00m\n\u001b[32m    685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m686\u001b[39m     model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[38;5;66;03m# Convert system_prompt to SystemMessage if needed\u001b[39;00m\n\u001b[32m    689\u001b[39m system_message: SystemMessage | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\langchainupdated\\.venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:316\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m     warnings.warn(\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    312\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    313\u001b[39m     )\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    322\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\langchainupdated\\.venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:365\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatCohere(model=model, **kwargs)\n\u001b[32m    364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgoogle_vertexai\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m     \u001b[43m_check_pkg\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlangchain_google_vertexai\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_vertexai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatVertexAI\n\u001b[32m    368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatVertexAI(model=model, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Generative AI\\langchainupdated\\.venv\\Lib\\site-packages\\langchain\\chat_models\\base.py:537\u001b[39m, in \u001b[36m_check_pkg\u001b[39m\u001b[34m(pkg, pkg_kebab)\u001b[39m\n\u001b[32m    535\u001b[39m pkg_kebab = pkg_kebab \u001b[38;5;28;01mif\u001b[39;00m pkg_kebab \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pkg.replace(\u001b[33m\"\u001b[39m\u001b[33m_\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    536\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnable to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please install with `pip install -U \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpkg_kebab\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m537\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n",
      "\u001b[31mImportError\u001b[39m: Unable to import langchain_google_vertexai. Please install with `pip install -U langchain-google-vertexai`"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from langchain.agents import create_agent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "@dataclass\n",
    "class ContactInfo:\n",
    "    \"\"\"Contact information for a person\"\"\"\n",
    "    name: str\n",
    "    email: str\n",
    "    phone: str\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0\n",
    ")\n",
    " \n",
    "agent = create_agent(\n",
    "    model = llm,\n",
    "    response_format = ContactInfo    # Autoselecs provider stratergy\n",
    ")\n",
    "\n",
    "result = agent.invoke({\n",
    "    \"messages\":[{\"role\":\"user\", \"content\":\"Extract contact info from: John Doe, john@example.com, (555) 123-4567\"}]\n",
    "})  \n",
    "\n",
    "print(result['structured_response'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fee45d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
